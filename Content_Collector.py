import os
import re
from typing import Union, Iterable, List, Dict
from langextract.data import Document

class DocumentCollector:
    """æ”¶é›†æ–‡æª”å…§å®¹ä¸¦è½‰æ›ç‚ºLangExtractæ‰€éœ€çš„Documentå°è±¡"""
    
    def __init__(self, file_path: str, extensions: List[str]):
        self.file_path = file_path
        self.extensions = extensions
        self.documents: List[Document] = []
    
    def _enhanced_regex_extraction(self, documents: List[Dict]) -> List[Dict]:
        """Enhanced regex-based extraction with better patterns"""
        
        extracted_docs = []
        
        for doc in documents:
            metadata = {
                'service': 'unknown',
                'version': 'unknown',
                'doc_type': 'reference', 
                'rate_limits': [],
                'deprecated': False
            }
            
            title = doc.get('title', '')
            content = doc['content']
            
            # Extract service name from title
            service_match = re.search(r'([\w\s]+(?:API|Service))', title)
            if service_match:
                metadata['service'] = service_match.group(1).strip()
            
            # Extract version number
            version_match = re.search(r'v?([\d.]+)', title)
            if version_match:
                metadata['version'] = version_match.group(1)
            
            # Determine document type
            if 'troubleshooting' in title.lower():
                metadata['doc_type'] = 'troubleshooting'
            elif 'guide' in title.lower():
                metadata['doc_type'] = 'guide'
            else:
                metadata['doc_type'] = 'reference'
            
            # Extract rate limits
            rate_matches = re.findall(r'(\d+)\s*(?:requests?|req)[/\s]*(?:per\s*)?min', content.lower())
            metadata['rate_limits'] = [f"{r} req/min" for r in rate_matches]
            
            # Check for deprecation
            if 'deprecated' in content.lower():
                metadata['deprecated'] = True
            
            extracted_docs.append({
                'id': doc['id'],
                'title': doc['title'], 
                'content': doc['content'],
                'metadata': metadata
            })
        
        return extracted_docs

    def find_files_with_extensions(self) -> List[str]:
        """
        éæ­¸æŸ¥æ‰¾æŒ‡å®šå‰¯æª”åçš„æ–‡ä»¶
        
        :return: æ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
        """
        found_files = []

        if not os.path.isdir(self.file_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç›®éŒ„: {os.path.abspath(self.file_path)}")

        for dirpath, _, filenames in os.walk(self.file_path):
            for filename in filenames:
                if any(filename.endswith(ext) for ext in self.extensions):
                    file_path = os.path.join(dirpath, filename)
                    found_files.append(file_path)
                    print(f"æ‰¾åˆ°æ–‡ä»¶: {file_path}")

        print(f"æ‰¾åˆ°ç¨‹å¼æ–‡ä»¶å…± {len(found_files)} å€‹ã€‚")
        return found_files

    def load_file_content(self, file_path: str) -> str:
        """
        å®‰å…¨åœ°è¼‰å…¥å–®å€‹æ–‡ä»¶å…§å®¹
        
        :param file_path: æ–‡ä»¶è·¯å¾‘
        :return: æ–‡ä»¶å…§å®¹ï¼Œå‡ºéŒ¯æ™‚è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                print(f"âœ… æˆåŠŸè¼‰å…¥: {file_path} ({len(content)} å­—ç¬¦)")
                return content
        except UnicodeDecodeError:
            # å˜—è©¦å…¶ä»–ç·¨ç¢¼
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    content = f.read()
                    print(f"âœ… æˆåŠŸè¼‰å…¥ (GBKç·¨ç¢¼): {file_path}")
                    return content
            except Exception as e:
                print(f"âŒ ç·¨ç¢¼éŒ¯èª¤: {file_path} - {e}")
                return ""
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")
            return ""
        except PermissionError:
            print(f"âŒ æ²’æœ‰æ¬Šé™è®€å–æª”æ¡ˆ: {file_path}")
            return ""
        except Exception as e:
            print(f"âŒ è®€å–æª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return ""

    def create_langextract_document(self, file_path: str, content: str) -> Document:
        """
        å‰µå»ºLangExtract Documentå°è±¡
        
        :param file_path: æ–‡ä»¶è·¯å¾‘
        :param content: æ–‡ä»¶å…§å®¹
        :return: LangExtract Documentå°è±¡
        """
        # ä½¿ç”¨ç›¸å°è·¯å¾‘ä½œç‚ºdocument_idï¼Œæ›´ç°¡æ½”
        relative_path = os.path.relpath(file_path, self.file_path)
        
        # å‰µå»ºDocumentæ™‚ï¼Œç¢ºä¿åƒæ•¸æ­£ç¢º
        doc = Document(
            text=content,
            document_id=relative_path,
            # å¯ä»¥æ·»åŠ metadata
            # metadata={
            #     "full_path": file_path,
            #     "extension": Path(file_path).suffix,
            #     "size": len(content)
            # }
        )
        return doc

    def collect_documents(self) -> List[Document]:
        """
        æ”¶é›†æ‰€æœ‰æ–‡æª”ä¸¦è½‰æ›ç‚ºLangExtract Documentå°è±¡
        
        :return: Documentå°è±¡åˆ—è¡¨
        """
        # æ¸…ç©ºä¹‹å‰çš„çµæœ
        self.documents = []
        
        found_files = self.find_files_with_extensions()
        print(f"æº–å‚™è¼‰å…¥ {len(found_files)} å€‹æª”æ¡ˆ...")

        successful_count = 0
        
        for file_path in found_files:
            content = self.load_file_content(file_path)
            
            # åªè™•ç†éç©ºå…§å®¹
            if content and content.strip():
                try:
                    doc = self.create_langextract_document(file_path, content)
                    self.documents.append(doc)
                    successful_count += 1
                    
                    # é¡¯ç¤ºæ–‡ä»¶å…§å®¹é è¦½
                    preview = content[:100].replace('\n', '\\n')
                    print(f"ğŸ“„ æ–‡æª”å‰µå»ºæˆåŠŸ: {os.path.basename(file_path)} - é è¦½: {preview}...")
                    
                except Exception as e:
                    print(f"âŒ å‰µå»ºæ–‡æª”å¤±æ•— {file_path}: {e}")
                    continue
            else:
                print(f"âš ï¸ è·³éç©ºæ–‡ä»¶: {file_path}")

        print(f"\nâœ… æˆåŠŸè™•ç† {successful_count}/{len(found_files)} å€‹æ–‡ä»¶")
        print(f"ğŸ“‹ ç¸½å…±å‰µå»º {len(self.documents)} å€‹Documentå°è±¡")
        
        return self.documents

    def get_documents_for_langextract(self) -> List[Document]:
        """
        ç²å–é©ç”¨æ–¼LangExtractçš„Documentåˆ—è¡¨
        
        :return: é©ç”¨æ–¼text_or_documentsåƒæ•¸çš„Documentåˆ—è¡¨
        """
        if not self.documents:
            self.collect_documents()
        
        # é©—è­‰Documentå°è±¡
        valid_documents = []
        for doc in self.documents:
            if hasattr(doc, 'text') and hasattr(doc, 'document_id'):
                if doc.text and doc.text.strip():
                    valid_documents.append(doc)
                else:
                    print(f"âš ï¸ è·³éç©ºå…§å®¹æ–‡æª”: {doc.document_id}")
            else:
                print(f"âŒ ç„¡æ•ˆçš„Documentå°è±¡: {doc}")
        
        print(f"ğŸ“Š æœ€çµ‚æœ‰æ•ˆæ–‡æª”æ•¸é‡: {len(valid_documents)}")
        return valid_documents
